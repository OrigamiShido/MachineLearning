{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "使用horseColicTraining.txt 文件作为训练集（每行包含了病马的20\n",
    "个特征和是否死亡的标签），horseColicTest.txt 作为测试集，利用\n",
    "Logistic回归预测病马的死亡率。计算多次迭代后的平均错误率。"
   ],
   "id": "a37b8634dbb2fdb7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T13:13:38.344778Z",
     "start_time": "2024-10-14T13:13:38.227171Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "dataTrain=pd.read_csv('C:/Users/Admin/Desktop/WHU study/programming/python/MachineLearning/exp2/horseColicTraining.txt', sep='\\t', header=None).head()\n",
    "dataTest=pd.read_csv('C:/Users/Admin/Desktop/WHU study/programming/python/MachineLearning/exp2/horseColicTest.txt', sep='\\t', header=None).head()\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1.0/(1+np.exp(-x))\n",
    "\n",
    "def gradascent(dataMatrix, classLabels):\n",
    "    dataMatrix=np.mat(dataMatrix)\n",
    "    labelMat=np.mat(classLabels).transpose()\n",
    "    m,n=np.shape(dataMatrix)\n",
    "    alpha=0.001\n",
    "    maxCycles=500\n",
    "    weights=np.ones((n,1))\n",
    "    for k in range(maxCycles):\n",
    "        h=sigmoid(dataMatrix*weights)\n",
    "        error=(labelMat-h)\n",
    "        weights=weights+alpha*dataMatrix.transpose()*error\n",
    "    return weights\n",
    "\n",
    "def stocGradAscent(dataMatrix,classLabels,numIter=200):\n",
    "    m,n=np.shape(dataMatrix)\n",
    "    weights=np.ones(n)\n",
    "    for j in range(numIter):\n",
    "        dataIndex=range(m)\n",
    "        for i in range(m):\n",
    "            alpha=4/(1.0+j+i)+0.01\n",
    "            randIndex=int(np.random.uniform(0,len(dataIndex)))\n",
    "            h=sigmoid(sum(dataMatrix[randIndex]*weights))\n",
    "            error=classLabels[randIndex]-h\n",
    "            weights=weights+alpha*error*dataMatrix[randIndex]\n",
    "            del(dataIndex[randIndex])\n",
    "    return weights\n",
    "\n",
    "def classifyVector(x,weights):\n",
    "    prob=sigmoid(float(x*weights))\n",
    "    if prob>0.5:\n",
    "        return 1.0\n",
    "    else:\n",
    "        return 0.0 \n",
    "\n",
    "# print(dataTrain[dataTrain.columns[0:-1]])\n",
    "weight=stocGradAscent(np.mat(dataTrain[dataTrain.columns[0:-1]]),np.mat(dataTrain[dataTrain.columns[-1]]))\n",
    "print(weight)\n",
    "y_pred=[]\n",
    "# print(sum(np.mat(dataTest[dataTest.columns[0:-1]].iloc[0])*weight))\n",
    "for i in range(len(dataTest)):\n",
    "    y_pred.append(classifyVector(np.mat(dataTest[dataTest.columns[0:-1]].iloc[i]),weight))\n",
    "print(accuracy_score(dataTest[dataTest.columns[-1]],y_pred))\n",
    "print(confusion_matrix(dataTest[dataTest.columns[-1]],y_pred))\n",
    "print(classification_report(dataTest[dataTest.columns[-1]],y_pred))\n"
   ],
   "id": "c78e94e2ed944cac",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (1,21) and (1,21) not aligned: 21 (dim 1) != 1 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[24], line 49\u001B[0m\n\u001B[0;32m     46\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;241m0.0\u001B[39m \n\u001B[0;32m     48\u001B[0m \u001B[38;5;66;03m# print(dataTrain[dataTrain.columns[0:-1]])\u001B[39;00m\n\u001B[1;32m---> 49\u001B[0m weight\u001B[38;5;241m=\u001B[39mstocGradAscent(np\u001B[38;5;241m.\u001B[39mmat(dataTrain[dataTrain\u001B[38;5;241m.\u001B[39mcolumns[\u001B[38;5;241m0\u001B[39m:\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]]),np\u001B[38;5;241m.\u001B[39mmat(dataTrain[dataTrain\u001B[38;5;241m.\u001B[39mcolumns[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]]))\n\u001B[0;32m     50\u001B[0m \u001B[38;5;28mprint\u001B[39m(weight)\n\u001B[0;32m     51\u001B[0m y_pred\u001B[38;5;241m=\u001B[39m[]\n",
      "Cell \u001B[1;32mIn[24], line 35\u001B[0m, in \u001B[0;36mstocGradAscent\u001B[1;34m(dataMatrix, classLabels, numIter)\u001B[0m\n\u001B[0;32m     33\u001B[0m alpha\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m4\u001B[39m\u001B[38;5;241m/\u001B[39m(\u001B[38;5;241m1.0\u001B[39m\u001B[38;5;241m+\u001B[39mj\u001B[38;5;241m+\u001B[39mi)\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m0.01\u001B[39m\n\u001B[0;32m     34\u001B[0m randIndex\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mint\u001B[39m(np\u001B[38;5;241m.\u001B[39mrandom\u001B[38;5;241m.\u001B[39muniform(\u001B[38;5;241m0\u001B[39m,\u001B[38;5;28mlen\u001B[39m(dataIndex)))\n\u001B[1;32m---> 35\u001B[0m h\u001B[38;5;241m=\u001B[39msigmoid(\u001B[38;5;28msum\u001B[39m(dataMatrix[randIndex]\u001B[38;5;241m*\u001B[39mweights))\n\u001B[0;32m     36\u001B[0m error\u001B[38;5;241m=\u001B[39mclassLabels[randIndex]\u001B[38;5;241m-\u001B[39mh\n\u001B[0;32m     37\u001B[0m weights\u001B[38;5;241m=\u001B[39mweights\u001B[38;5;241m+\u001B[39malpha\u001B[38;5;241m*\u001B[39merror\u001B[38;5;241m*\u001B[39mdataMatrix[randIndex]\n",
      "File \u001B[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\numpy\\matrixlib\\defmatrix.py:219\u001B[0m, in \u001B[0;36mmatrix.__mul__\u001B[1;34m(self, other)\u001B[0m\n\u001B[0;32m    216\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__mul__\u001B[39m(\u001B[38;5;28mself\u001B[39m, other):\n\u001B[0;32m    217\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(other, (N\u001B[38;5;241m.\u001B[39mndarray, \u001B[38;5;28mlist\u001B[39m, \u001B[38;5;28mtuple\u001B[39m)) :\n\u001B[0;32m    218\u001B[0m         \u001B[38;5;66;03m# This promotes 1-D vectors to row vectors\u001B[39;00m\n\u001B[1;32m--> 219\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m N\u001B[38;5;241m.\u001B[39mdot(\u001B[38;5;28mself\u001B[39m, asmatrix(other))\n\u001B[0;32m    220\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m isscalar(other) \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(other, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m__rmul__\u001B[39m\u001B[38;5;124m'\u001B[39m) :\n\u001B[0;32m    221\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m N\u001B[38;5;241m.\u001B[39mdot(\u001B[38;5;28mself\u001B[39m, other)\n",
      "\u001B[1;31mValueError\u001B[0m: shapes (1,21) and (1,21) not aligned: 21 (dim 1) != 1 (dim 0)"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "5.采用sklearn.linear_model.LogisticRegression实现上述数据集Logistic\n",
    "回归预测病马死亡率。"
   ],
   "id": "c90db13f02895403"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T13:16:05.128226Z",
     "start_time": "2024-10-14T13:16:04.876145Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "dataTrain=pd.read_csv('C:/Users/Admin/Desktop/WHU study/programming/python/MachineLearning/exp2/horseColicTraining.txt', sep='\\t', header=None).head()\n",
    "dataTest=pd.read_csv('C:/Users/Admin/Desktop/WHU study/programming/python/MachineLearning/exp2/horseColicTest.txt', sep='\\t', header=None).head()\n",
    "\n",
    "model=LogisticRegression()\n",
    "model.fit(dataTrain[dataTrain.columns[0:-1]],dataTrain[dataTrain.columns[-1]])\n",
    "y_pred=model.predict(dataTest[dataTest.columns[0:-1]])\n",
    "print(accuracy_score(dataTest[dataTest.columns[-1]],y_pred))\n",
    "print(confusion_matrix(dataTest[dataTest.columns[-1]],y_pred))\n",
    "print(classification_report(dataTest[dataTest.columns[-1]],y_pred))\n"
   ],
   "id": "7fab6aae95785d27",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8\n",
      "[[1 0]\n",
      " [1 3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67         1\n",
      "           1       1.00      0.75      0.86         4\n",
      "\n",
      "    accuracy                           0.80         5\n",
      "   macro avg       0.75      0.88      0.76         5\n",
      "weighted avg       0.90      0.80      0.82         5\n",
      "\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "通过访问：\n",
    "http://archive.ics.uci.edu/ml/machine-learning-databases/horsecolic/\n",
    "horse-colic.data 中提供的病马原始数据，采用sklearn.impute 中\n",
    "SimpleImputer对原始缺失数据进行处理（处理策略不限定，如：特殊\n",
    "值、均值等）。"
   ],
   "id": "d0d1d55b9e51e396"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T14:27:11.569876Z",
     "start_time": "2024-10-14T14:27:10.739286Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data=pd.read_csv('http://archive.ics.uci.edu/ml/machine-learning-databases/horse-colic/horse-colic.data',sep=' ')\n",
    "data=data.replace('?',np.nan)\n",
    "imp=SimpleImputer(strategy='mean')\n",
    "data=imp.fit_transform(data)\n",
    "data=pd.DataFrame(data)\n",
    "dataTrain,dataTest=train_test_split(data,test_size=0.2)\n",
    "model=LogisticRegression()\n",
    "model.fit(dataTrain[dataTrain.columns[0:-1]],dataTrain[dataTrain.columns[-1]])\n",
    "y_pred=model.predict(dataTest[dataTest.columns[0:-1]])\n",
    "print(accuracy_score(dataTest[dataTest.columns[-1]],y_pred))\n",
    "print(confusion_matrix(dataTest[dataTest.columns[-1]],y_pred))\n",
    "print(classification_report(dataTest[dataTest.columns[-1]],y_pred))\n"
   ],
   "id": "9dfacfb36e45a38c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    2        1 530101 38.50  66 28  3 3.1  ? 2.1  ... 45.00 8.40   ?.4 ?.5  \\\n",
      "1   1   534817   39.2    88  20  ?  ?   4  1   3  ...    85    2     2   3   \n",
      "2   1   530334  38.30    40  24  1  1   3  1   3  ...  6.70    ?     ?   1   \n",
      "1   9  5290409  39.10   164  84  4  1   6  2   2  ...  7.20    3  5.30   2   \n",
      "2   1   530255  37.30   104  35  ?  ?   6  2   ?  ...  7.40    ?     ?   2   \n",
      "2   1   528355      ?     ?   ?  2  1   3  1   2  ...     ?    ?     ?   1   \n",
      ".. ..      ...    ...   ...  .. .. ..  .. ..  ..  ...   ...  ...   ...  ..   \n",
      "1   1   533886      ?   120  70  4  ?   4  2   2  ...    65    ?     ?   3   \n",
      "2   1   527702  37.20    72  24  3  2   4  2   4  ...     ?    3  3.30   3   \n",
      "1   1   529386  37.50    72  30  4  3   4  1   4  ...  6.80    ?     ?   2   \n",
      "1   1   530612  36.50   100  24  3  3   3  1   3  ...  6.00    3  3.40   1   \n",
      "1   1   534618   37.2    40  20  ?  ?   ?  ?   ?  ...    62    1     1   3   \n",
      "\n",
      "   2.2   2.3 11300 00000 00000.1 2.4  \n",
      "1    2  2208     0     0       2 NaN  \n",
      "2    2     0     0     0       1 NaN  \n",
      "1    1  2208     0     0       1 NaN  \n",
      "2    2  4300     0     0       2 NaN  \n",
      "2    2     0     0     0       2 NaN  \n",
      "..  ..   ...   ...   ...     ...  ..  \n",
      "1    2  3205     0     0       2 NaN  \n",
      "2    1  2208     0     0       1 NaN  \n",
      "1    1  3205     0     0       2 NaN  \n",
      "1    1  2208     0     0       1 NaN  \n",
      "1    2  6112     0     0       2 NaN  \n",
      "\n",
      "[299 rows x 28 columns]\n",
      "    2        1 530101 38.50   66   28    3  3.1    ?  2.1  ... 45.00 8.40  \\\n",
      "1   1   534817   39.2    88   20  NaN  NaN    4    1    3  ...    85    2   \n",
      "2   1   530334  38.30    40   24    1    1    3    1    3  ...  6.70  NaN   \n",
      "1   9  5290409  39.10   164   84    4    1    6    2    2  ...  7.20    3   \n",
      "2   1   530255  37.30   104   35  NaN  NaN    6    2  NaN  ...  7.40  NaN   \n",
      "2   1   528355    NaN   NaN  NaN    2    1    3    1    2  ...   NaN  NaN   \n",
      ".. ..      ...    ...   ...  ...  ...  ...  ...  ...  ...  ...   ...  ...   \n",
      "1   1   533886    NaN   120   70    4  NaN    4    2    2  ...    65  NaN   \n",
      "2   1   527702  37.20    72   24    3    2    4    2    4  ...   NaN    3   \n",
      "1   1   529386  37.50    72   30    4    3    4    1    4  ...  6.80  NaN   \n",
      "1   1   530612  36.50   100   24    3    3    3    1    3  ...  6.00    3   \n",
      "1   1   534618   37.2    40   20  NaN  NaN  NaN  NaN  NaN  ...    62    1   \n",
      "\n",
      "     ?.4 ?.5 2.2   2.3 11300 00000 00000.1 2.4  \n",
      "1      2   3   2  2208     0     0       2 NaN  \n",
      "2    NaN   1   2     0     0     0       1 NaN  \n",
      "1   5.30   2   1  2208     0     0       1 NaN  \n",
      "2    NaN   2   2  4300     0     0       2 NaN  \n",
      "2    NaN   1   2     0     0     0       2 NaN  \n",
      "..   ...  ..  ..   ...   ...   ...     ...  ..  \n",
      "1    NaN   3   2  3205     0     0       2 NaN  \n",
      "2   3.30   3   1  2208     0     0       1 NaN  \n",
      "1    NaN   2   1  3205     0     0       2 NaN  \n",
      "1   3.40   1   1  2208     0     0       1 NaN  \n",
      "1      1   3   2  6112     0     0       2 NaN  \n",
      "\n",
      "[299 rows x 28 columns]\n",
      "0.6166666666666667\n",
      "[[ 6 18]\n",
      " [ 5 31]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.55      0.25      0.34        24\n",
      "         2.0       0.63      0.86      0.73        36\n",
      "\n",
      "    accuracy                           0.62        60\n",
      "   macro avg       0.59      0.56      0.54        60\n",
      "weighted avg       0.60      0.62      0.57        60\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\impute\\_base.py:577: UserWarning: Skipping features without any observed values: ['2.4']. At least one non-missing value is needed for imputation with strategy='mean'.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "execution_count": 52
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
