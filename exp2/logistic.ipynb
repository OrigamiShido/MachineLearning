{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "使用horseColicTraining.txt 文件作为训练集（每行包含了病马的20\n",
    "个特征和是否死亡的标签），horseColicTest.txt 作为测试集，利用\n",
    "Logistic回归预测病马的死亡率。计算多次迭代后的平均错误率。"
   ],
   "id": "a37b8634dbb2fdb7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T10:02:41.283238Z",
     "start_time": "2024-10-16T10:01:23.690674Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from numba.cpython.builtins import max_iterable\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "dataTrain=pd.read_csv('C:/Users/Admin/Desktop/WHU study/programming/python/MachineLearning/exp2/horseColicTraining.txt', sep='\\t', header=None)\n",
    "dataTest=pd.read_csv('C:/Users/Admin/Desktop/WHU study/programming/python/MachineLearning/exp2/horseColicTest.txt', sep='\\t', header=None)\n",
    "\n",
    "def sigmoid(x):\n",
    "    if x>=0:\n",
    "        return 1.0/(1+np.exp(-x))\n",
    "    else:\n",
    "        return np.exp(x)/(1+np.exp(x))\n",
    "\n",
    "def gradascent(dataMatrix, classLabels):\n",
    "    dataMatrix=np.mat(dataMatrix)\n",
    "    labelMat=np.mat(classLabels).transpose()\n",
    "    m,n=np.shape(dataMatrix)\n",
    "    alpha=0.001\n",
    "    maxCycles=500\n",
    "    weights=np.ones((n,1))\n",
    "    for k in range(maxCycles):\n",
    "        h=sigmoid(dataMatrix*weights)\n",
    "        error=(labelMat-h)\n",
    "        weights=weights+alpha*dataMatrix.transpose()*error# errormay\n",
    "    return weights\n",
    "\n",
    "def stocGradAscent(dataMatrix,classLabels,numIter=200):\n",
    "    m,n=np.shape(dataMatrix)\n",
    "    weights=np.ones(n)\n",
    "    for j in range(numIter):\n",
    "        dataIndex=list(range(m))\n",
    "        for i in range(m):\n",
    "            alpha=4/(1.0+j+i)+0.01\n",
    "            randIndex=int(np.random.uniform(0,len(dataIndex)))\n",
    "            h=sigmoid(sum(dataMatrix[randIndex]*weights))\n",
    "            error=classLabels[randIndex]-h\n",
    "            weights=weights+alpha*error*dataMatrix[randIndex]\n",
    "            del(dataIndex[randIndex])\n",
    "    return weights\n",
    "\n",
    "def classifyVector(x,weights):\n",
    "    prob=sigmoid(sum(x*weights))\n",
    "    if prob>0.5:\n",
    "        return 1.0\n",
    "    else:\n",
    "        return 0.0 \n",
    "\n",
    "# print(dataTrain[dataTrain.columns[0:-1]])\n",
    "weight=stocGradAscent(np.array(dataTrain[dataTrain.columns[0:-1]]),np.array(dataTrain[dataTrain.columns[-1]]))\n",
    "print(weight)\n",
    "y_pred=[]\n",
    "# print(sum(np.mat(dataTest[dataTest.columns[0:-1]].iloc[0])*weight))\n",
    "for i in range(len(dataTest)):\n",
    "    y_pred.append(classifyVector(np.array(dataTest[dataTest.columns[0:-1]].iloc[i]),weight))\n",
    "print(accuracy_score(dataTest[dataTest.columns[-1]],y_pred))\n",
    "print(confusion_matrix(dataTest[dataTest.columns[-1]],y_pred))\n",
    "print(classification_report(dataTest[dataTest.columns[-1]],y_pred))\n",
    "\n",
    "error_rate=[]\n",
    "for i in range(100):\n",
    "    weight=stocGradAscent(np.array(dataTrain[dataTrain.columns[0:-1]]),np.array(dataTrain[dataTrain.columns[-1]]))\n",
    "    y_pred=[]\n",
    "    for j in range(len(dataTest)):\n",
    "        y_pred.append(classifyVector(np.array(dataTest[dataTest.columns[0:-1]].iloc[j]),weight))\n",
    "    error_rate.append(1-accuracy_score(dataTest[dataTest.columns[-1]],y_pred))\n",
    "    \n",
    "print(np.mean(error_rate))\n"
   ],
   "id": "c78e94e2ed944cac",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 24.93947515  -4.07612611   4.14354925  -3.53393903   2.97848016\n",
      "  -9.86649833  -1.1182112  -19.59087337  -7.50475604 -20.6928954\n",
      "  43.21792789 -46.44507533  55.8787422   19.9962685  -30.00178965\n",
      "   8.21021646  -4.8978743    0.44590411   0.27392694 -16.96728392\n",
      "  -5.80955553]\n",
      "0.6268656716417911\n",
      "[[17  3]\n",
      " [22 25]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.85      0.58        20\n",
      "           1       0.89      0.53      0.67        47\n",
      "\n",
      "    accuracy                           0.63        67\n",
      "   macro avg       0.66      0.69      0.62        67\n",
      "weighted avg       0.76      0.63      0.64        67\n",
      "\n",
      "0.36970149253731344\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "5.采用sklearn.linear_model.LogisticRegression实现上述数据集Logistic\n",
    "回归预测病马死亡率。"
   ],
   "id": "c90db13f02895403"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T09:43:09.112446Z",
     "start_time": "2024-10-16T09:43:09.059727Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "dataTrain=pd.read_csv('C:/Users/Admin/Desktop/WHU study/programming/python/MachineLearning/exp2/horseColicTraining.txt', sep='\\t', header=None)\n",
    "dataTest=pd.read_csv('C:/Users/Admin/Desktop/WHU study/programming/python/MachineLearning/exp2/horseColicTest.txt', sep='\\t', header=None)\n",
    "\n",
    "model=LogisticRegression(max_iter=10000)\n",
    "model.fit(dataTrain[dataTrain.columns[0:-1]],dataTrain[dataTrain.columns[-1]])\n",
    "y_pred=model.predict(dataTest[dataTest.columns[0:-1]])\n",
    "print(accuracy_score(dataTest[dataTest.columns[-1]],y_pred))\n",
    "print(confusion_matrix(dataTest[dataTest.columns[-1]],y_pred))\n",
    "print(classification_report(dataTest[dataTest.columns[-1]],y_pred))\n"
   ],
   "id": "7fab6aae95785d27",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7164179104477612\n",
      "[[12  8]\n",
      " [11 36]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.60      0.56        20\n",
      "           1       0.82      0.77      0.79        47\n",
      "\n",
      "    accuracy                           0.72        67\n",
      "   macro avg       0.67      0.68      0.67        67\n",
      "weighted avg       0.73      0.72      0.72        67\n",
      "\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "通过访问：\n",
    "http://archive.ics.uci.edu/ml/machine-learning-databases/horsecolic/\n",
    "horse-colic.data 中提供的病马原始数据，采用sklearn.impute 中\n",
    "SimpleImputer对原始缺失数据进行处理（处理策略不限定，如：特殊\n",
    "值、均值等）。"
   ],
   "id": "d0d1d55b9e51e396"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T09:00:34.240332Z",
     "start_time": "2024-10-16T09:00:33.928073Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# data=pd.read_csv('http://archive.ics.uci.edu/ml/machine-learning-databases/horse-colic/horse-colic.data',sep=' ',header=None)\n",
    "data=pd.read_csv('C:/Users/Admin/Desktop/WHU study/programming/python/MachineLearning/exp2/horse-colic.data',sep=' +',header=None,engine='python')\n",
    "data=data.replace('?',np.nan)\n",
    "data.drop(data.iloc[:,23:28],axis=1,inplace=True)\n",
    "data.drop(data.columns[2],axis=1,inplace=True)\n",
    "# imp=SimpleImputer(strategy='median')\n",
    "imp=SimpleImputer(strategy='constant',fill_value='0')\n",
    "data=imp.fit_transform(data)\n",
    "data=pd.DataFrame(data).astype('float64')\n",
    "dataTrain,dataTest=train_test_split(data,test_size=0.2)\n",
    "model=LogisticRegression(max_iter=10000)\n",
    "model.fit(dataTrain[dataTrain.columns[0:-1]],dataTrain[dataTrain.columns[-1]])\n",
    "y_pred=model.predict(dataTest[dataTest.columns[0:-1]])\n",
    "print(accuracy_score(dataTest[dataTest.columns[-1]],y_pred))\n",
    "print(confusion_matrix(dataTest[dataTest.columns[-1]],y_pred))\n",
    "print(classification_report(dataTest[dataTest.columns[-1]],y_pred,zero_division=1))\n"
   ],
   "id": "9dfacfb36e45a38c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6833333333333333\n",
      "[[31  5  1]\n",
      " [ 5  9  0]\n",
      " [ 7  1  1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.72      0.84      0.78        37\n",
      "         2.0       0.60      0.64      0.62        14\n",
      "         3.0       0.50      0.11      0.18         9\n",
      "\n",
      "    accuracy                           0.68        60\n",
      "   macro avg       0.61      0.53      0.53        60\n",
      "weighted avg       0.66      0.68      0.65        60\n",
      "\n"
     ]
    }
   ],
   "execution_count": 22
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
