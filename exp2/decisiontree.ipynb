{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "使用lenses.txt 中的隐形眼镜数据集，采用第三章中介绍的ID3 算法构建决策树。使用决策树，输入几组隐形眼镜特征数据，例如：'young','hyper','no','reduced'，'pre','hyper','no','normal'；等进行测试，预测隐形眼镜类型。",
   "id": "8e900e1edea0f"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-14T11:03:17.626Z",
     "start_time": "2024-10-14T11:03:17.574211Z"
    }
   },
   "source": [
    "import operator\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "def calcShannonEnt(dataset):\n",
    "    numEntries=len(dataset)\n",
    "    labelCounts={}\n",
    "    for featVec in dataset:\n",
    "        currentLabel=featVec[-1]\n",
    "        if currentLabel not in labelCounts.keys():\n",
    "            labelCounts[currentLabel]=0\n",
    "        labelCounts[currentLabel]+=1\n",
    "    shannonEnt=0.0\n",
    "    for key in labelCounts:\n",
    "        prob=float(labelCounts[key])/numEntries\n",
    "        shannonEnt-=prob*math.log(prob,2)\n",
    "    return shannonEnt\n",
    "\n",
    "def splitDataSet(dataset, axis, value):\n",
    "    retDataSet=[]\n",
    "    for featVec in dataset:\n",
    "        if featVec[axis]==value:\n",
    "            reducedFeatVec=featVec[:axis]\n",
    "            reducedFeatVec.extend(featVec[axis+1:])\n",
    "            retDataSet.append(reducedFeatVec)\n",
    "    return retDataSet\n",
    "\n",
    "def chooseBestFeature(dataset):\n",
    "    numFeatures=len(dataset[0])-1\n",
    "    baseEntropy=calcShannonEnt(dataset)\n",
    "    bestInfoGain=0.0\n",
    "    bestFeature=-1\n",
    "    for i in range(numFeatures):\n",
    "        featList=[example[i] for example in dataset]\n",
    "        uniqueVals=set(featList)\n",
    "        newEntropy=0.0\n",
    "        for value in uniqueVals:\n",
    "            subDataset=splitDataSet(dataset,i,value)\n",
    "            prob=len(subDataset)/float(len(dataset))\n",
    "            newEntropy+=prob*calcShannonEnt(subDataset)\n",
    "        infogain=baseEntropy-newEntropy\n",
    "        if(infogain>bestInfoGain):\n",
    "            bestInfoGain=infogain\n",
    "            bestFeature=i\n",
    "    return bestFeature\n",
    "\n",
    "def majorityCnt(typeList):\n",
    "    classCount={}\n",
    "    for vote in typeList:\n",
    "        if vote not in classCount.keys():\n",
    "            classCount[vote]=0\n",
    "        classCount[vote]+=1\n",
    "    sortedClassCount=sorted(classCount.iteritems(),key=operator.itemgetter(1),reverse=True)\n",
    "    return sortedClassCount[0][0]\n",
    "\n",
    "def id3(dataset,labels):\n",
    "    typeList=[example[-1] for example in dataset]\n",
    "    if typeList.count(typeList[0])==len(typeList):\n",
    "        return typeList[0]\n",
    "    if len(dataset[0])==1:\n",
    "        return majorityCnt(typeList)\n",
    "    bestFeat=chooseBestFeature(dataset)\n",
    "    bestFeatLabel=labels[bestFeat]\n",
    "    decisionTree={bestFeatLabel:{}}\n",
    "    del(labels[bestFeat])\n",
    "    featValues=[example[bestFeat] for example in dataset]\n",
    "    uniqueVals=set(featValues)\n",
    "    for value in uniqueVals:\n",
    "        subLabels=labels[:]\n",
    "        decisionTree[bestFeatLabel][value]=id3(splitDataSet(dataset,bestFeat,value),subLabels)\n",
    "    return decisionTree\n",
    "\n",
    "# def plotNode(nodeTxt,centerPt,parentPt,nodeType):\n",
    "#     createPlot.ax1.annotate(nodeTxt,xy=parentPt,xycoords='axes fraction',xytext=centerPt,textcoords='axes fraction', va=\"center\",ha=\"center\",bbox=nodeType,arrowprops=arrow_args)\n",
    "# \n",
    "# # def createPlot():\n",
    "# #     fig=plt.figure(1,facecolor='white')\n",
    "# #     plt.clf()\n",
    "# #     createPlot.ax1=plt.subplot(111,frameon=False)\n",
    "# #     plotNode('决策节点',(0.5,0.1),(0.1,0.5),decisionNode)\n",
    "# #     plotNode('叶节点',(0.8,0.1),(0.3,0.8),leafNode)\n",
    "# #     plt.show()\n",
    "# \n",
    "# def getNumLeafs(tree):\n",
    "#     numLeafs=0\n",
    "#     firstStr=list(tree.keys())[0]\n",
    "#     secondDict=tree[firstStr]\n",
    "#     for key in secondDict.keys():\n",
    "#         if type(secondDict[key]).__name__=='dict':\n",
    "#             numLeafs+=getNumLeafs(secondDict[key])\n",
    "#         else:\n",
    "#             numLeafs+=1\n",
    "#     return numLeafs\n",
    "# \n",
    "# def getTreeDepth(tree):\n",
    "#     maxDepth=0\n",
    "#     firstStrr=list(tree.keys())[0]\n",
    "#     secondDict=tree[firstStrr]\n",
    "#     for key in secondDict.keys():\n",
    "#         if type(secondDict[key]).__name__=='dict':\n",
    "#             thisDepth=1+getTreeDepth(secondDict[key])\n",
    "#         else:\n",
    "#             thisDepth=1\n",
    "#         if thisDepth>maxDepth:\n",
    "#             maxDepth=thisDepth\n",
    "#     return maxDepth\n",
    "# \n",
    "# def plotMidText(cntrPt,parentPt,txtString):\n",
    "#     xMid=(parentPt[0]-cntrPt[0])/2.0+cntrPt[0]\n",
    "#     yMid=(parentPt[1]-cntrPt[1])/2.0+cntrPt[1]\n",
    "#     createPlot.ax1.text()\n",
    "# \n",
    "# def plotTree(tree,parentPt, nodeTxt):\n",
    "#     numLeafs=getNumLeafs(tree)\n",
    "#     depth=getTreeDepth(tree)\n",
    "#     firstStr=list(tree.keys())[0]\n",
    "#     cntrPt=(plotTree.x0ff+(1.0+float(numLeafs))/2.0/plotTree.totalW,plotTree.y0ff)\n",
    "#     plotMidText(cntrPt,parentPt,nodeTxt)\n",
    "#     plotNode(firstStr,cntrPt,parentPt,decisionNode)\n",
    "#     secondDict=tree[firstStr]\n",
    "#     plotTree.y0ff=plotTree.y0ff-1.0/plotTree.totalD\n",
    "#     for key in secondDict.keys():\n",
    "#         if type(secondDict[key]).__name__=='dict':\n",
    "#             plotTree(secondDict[key],cntrPt,str(key))\n",
    "#         else:\n",
    "#             plotTree.x0ff=plotTree.x0ff+1.0/plotTree.totalW\n",
    "#             plotNode(secondDict[key],(plotTree.x0ff,plotTree.y0ff),cntrPt,leafNode)\n",
    "#             plotMidText((plotTree.x0ff,plotTree.y0ff),cntrPt,str(key))\n",
    "#     plotTree.y0ff=plotTree.y0ff+1.0/plotTree.totalD\n",
    "#     \n",
    "# def createPlot(inTree):\n",
    "#     fig=plt.figure(1,facecolor='white')\n",
    "#     fig.clf()\n",
    "#     axprops=dict(xticks=[],yticks=[])\n",
    "#     createPlot.ax1=plt.subplot(111,frameon=False,**axprops)\n",
    "#     plotTree.totalW=float(getNumLeafs(inTree))\n",
    "#     plotTree.totalD=float(getTreeDepth(inTree))\n",
    "#     plotTree.x0ff=-0.5/plotTree.totalW\n",
    "#     plotTree.y0ff=1.0\n",
    "#     plotTree(inTree,(0.5,1.0),'')\n",
    "#     plt.show()\n",
    "\n",
    "data=pd.read_csv(\"C:/Users/Admin/Desktop/WHU study/programming/python/MachineLearning/exp2/lenses.txt\",sep='\\t', header=None)\n",
    "data.head()# line1 age line2 prescript line3 astigmatic lie4 tearrate line5 lensetype\n",
    "\n",
    "# print(data[0,1,2,3].values.tolist())\n",
    "# print(data[4].tolist())\n",
    "\n",
    "datainput=data.values.tolist()\n",
    "labels=['age','prescript','astigmatic','tearRate']\n",
    "# print(datainput)\n",
    "# print(labels)\n",
    "decisiontree=id3(datainput,labels)\n",
    "print(decisiontree)\n",
    "\n",
    "# dataset=[[1,1,'yes'],[1,1,'yes'],[1,0,'no'],[0,1,'no'],[0,1,'no']]\n",
    "# labels=['no surfacing','flippers']\n",
    "# \n",
    "# print(calcShannonEnt(dataset))\n",
    "\n",
    "decisionNode=dict(boxstyle=\"sawtooth\",fc=\"0.8\")\n",
    "leafNode=dict(boxstyle=\"round4\",fc=\"0.8\")\n",
    "arrow_args=dict(arrowstyle=\"<-\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tearRate': {'reduced': 'no lenses', 'normal': {'astigmatic': {'no': {'age': {'pre': 'soft', 'young': 'soft', 'presbyopic': {'prescript': {'myope': 'no lenses', 'hyper': 'soft'}}}}, 'yes': {'prescript': {'myope': 'hard', 'hyper': {'age': {'pre': 'no lenses', 'young': 'hard', 'presbyopic': 'no lenses'}}}}}}}}\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "2 利用机器学习库sklearn中的决策树分类器DecisionTreeClassifier对\n",
    "Iris 数据集进行交叉验证，测试其准确率。\n",
    "\n",
    "3.利用机器学习库sklearn中的随机森林分类器RandomForestClassifier\n",
    "对Iris 数据集进行交叉验证，测试其准确率。"
   ],
   "id": "48379b68885ec40f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T11:08:55.546244Z",
     "start_time": "2024-10-14T11:08:55.486833Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "iris=datasets.load_iris()\n",
    "X=iris.data\n",
    "Y=iris.target\n",
    "\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.4)\n",
    "\n",
    "clf=DecisionTreeClassifier()\n",
    "clf.fit(X_train,Y_train)\n",
    "print(clf.score(X_test,Y_test))\n",
    "\n",
    "rfc=RandomForestClassifier(n_estimators=10)\n",
    "rfc.fit(X_train,Y_train)\n",
    "print(rfc.score(X_test,Y_test))"
   ],
   "id": "348e5495affec1ae",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9333333333333333\n",
      "0.9666666666666667\n"
     ]
    }
   ],
   "execution_count": 12
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
